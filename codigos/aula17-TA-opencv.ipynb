{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dsadm\\Desktop\\Inteligência Artificial\\IABD\\codigos\\aula17-TA-opencv.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m face_cascade \u001b[39m=\u001b[39m load_face_detection_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Realizar a detecção de rostos na imagem\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m detect_faces(image_path, face_cascade)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# Realizar a análise de expressões faciais (opcional)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m analyze_facial_expression(image_path)\n",
      "\u001b[1;32mc:\\Users\\dsadm\\Desktop\\Inteligência Artificial\\IABD\\codigos\\aula17-TA-opencv.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_faces\u001b[39m(image_path, face_cascade):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(image, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Detectar rostos na imagem\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dsadm/Desktop/Intelig%C3%AAncia%20Artificial/IABD/codigos/aula17-TA-opencv.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     faces \u001b[39m=\u001b[39m face_cascade\u001b[39m.\u001b[39mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39m\u001b[39m1.3\u001b[39m, minNeighbors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, minSize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m30\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Codigo open cv\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Função para carregar o modelo de detecção facial do OpenCV\n",
    "def load_face_detection_model():\n",
    "    return cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Função para realizar a detecção de rostos em uma imagem\n",
    "def detect_faces(image_path, face_cascade):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar rostos na imagem\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Desenhar retângulos ao redor dos rostos detectados\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Exibir a imagem com os rostos detectados\n",
    "    cv2.imshow('Detecção de Rostos', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Função para realizar a análise de expressões faciais usando um modelo PyTorch (opcional)\n",
    "def analyze_facial_expression(image_path):\n",
    "    # Carregar o modelo pré-treinado para análise de expressões faciais (exemplo: ResNet-18)\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Transformações para pré-processar a imagem\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Carregar e pré-processar a imagem\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = transform(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Realizar a inferência\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # Converter as probabilidades em uma expressão facial\n",
    "    _, predicted_idx = torch.max(output, 1)\n",
    "    expression_labels = ['Feliz', 'Triste', 'Surpreso', 'Bravo', 'Neutro']\n",
    "    predicted_expression = expression_labels[predicted_idx]\n",
    "\n",
    "    print(f'Expressão Facial Predita: {predicted_expression}')\n",
    "\n",
    "# Caminho para a imagem que será analisada\n",
    "image_path = 'im1.jpg'\n",
    "\n",
    "# Carregar o modelo de detecção facial\n",
    "face_cascade = load_face_detection_model()\n",
    "\n",
    "# Realizar a detecção de rostos na imagem\n",
    "detect_faces(image_path, face_cascade)\n",
    "\n",
    "# Realizar a análise de expressões faciais (opcional)\n",
    "analyze_facial_expression(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
